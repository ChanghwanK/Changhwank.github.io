{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"회사에서 쿠버네티스 기반으로 서비스를 약 1년정도 운영 중인 상태입니다. 2024년의 비즈니스 목표는 ‘우리 Platform을 Boxing하여 고객사에 딜리버리 하고 운영하는 것’이었습니다. 목표: 실제 고객사의 보안 요구사항을 충족 시키며 “우리 Platform을 ‘전달’ 하고 ‘운영’ 해야 한다.” (No Inbound Only OutBound) 돌아…","fields":{"slug":"/왜-쿠버네티스인가/"},"frontmatter":{"date":"February 07, 2025","title":"왜 쿠버네티스를 도입 했는가?","tags":["Kubernetes","DevOps"]},"rawMarkdownBody":"\n회사에서 쿠버네티스 기반으로 서비스를 약 1년정도 운영 중인 상태입니다. 2024년의 비즈니스 목표는 **‘우리 Platform을 Boxing하여 고객사에 딜리버리 하고 운영하는 것’**이었습니다.\n\n**목표:**\n\n> 실제 고객사의 보안 요구사항을 충족 시키며 **“우리 Platform을 ‘전달’ 하고 ‘운영’ 해야 한다.” (No Inbound Only OutBound)**\n>\n\n**돌아보면:**\n\n이 문제를 해결해야 할 때쯤인 23년 후반기에 팀장님 새롭게 오셨습니다. 새로오신 팀장님의 주요 커리어는 클라우드와 쿠버네티스였고 팀장님이 쿠버네티스를 잘 아신다는 이유로 쿠버네티스를 이용해 해결하고자 했습니다. 결론적으로 총 2개의 고객사에 쿠버네티스를 기반의 플랫폼 Boxing하여 딜리버리하였고 프로젝트를 성공적으로 운영하여 25년에도 다른 프로젝트들을 함께하게 되었습니다.  \n\n하지만 이 글의 트리거 라고 볼 수 있는데 지금 생각해보면 아쉬운 점이 존재합니다. **“왜 쿠버네티스를 사용했나요?”** 라고 질문한다면 논리적으로 대답하기 어렵고 스스로도 납득하기도 어렵습니다. 따라서 이 글을 작성하며 조금더 학습하며 앞으로  0 → 1 을 넘어 1 → 10 경험을 쌓을 수 있게 노력해볼 예정입니다.\n\n## **쿠버네티스란 무엇인가?**\n\n먼저, 쿠버네티스란 무엇이고 어떤 문제를 해결하기 위해 등장한 기술인지 알아보고자 합니다.\n\n> *Kubernetes is an open-source container orchestration system for automating software deployment, scaling, and management*  \n> by Wiki\n\n쿠버네티스에 대한 정의를 위키 백과에서는 ***“소프트웨어의 자동화된 배포와 스케일링 그리고 운영을 위한 오픈 소스 컨테이너 오케스트레이션 시스템이라 정의합니다.”***  즉, 쿠버네티스는 자동화된 컨테이너 운영 관리 도구인 것입니다. **‘오케스트레이션’** 이란 키워드가 등장하는데 그렇다면 오케스트레이션이란 무엇이고 보편적인 자동화와는 어떤 차이가 있기에 오케스트레이션이란 단어를 사용할까요?\n\n### **Automation vs Orchestration**\n\n**Automation 은 무언가를 새롭게 ‘배포’하고 메트릭을 ‘감지’ 하는 것에 집중합니다.**  즉, 자동화는 손쉽게 배포하고 이상 지표를 자동으로 감지할 수 있는 시스템을 만드는 것까지가 목표입니다. 하지만 운영/관리를 위해서는 보편적인 자동화로는 한계가 존재하는데 보편적인 자동화만으로는 이상 지표가 감지 되었을 때, 적절한 ‘후속 조치’를 사람이 진행해야 한다는 한계가 있습니다.\n\n**[수동 조취 케이스]**\n\n1. 컨테이너 내려간 경우, 서버에 접근하여 문제 있는 컨테이너를 제거하고 다시 컨테이너를 올려주어야 한다.\n2. 트래픽 증가로 인한 부하가 늘어나는 경우, 수동으로 컨테이너 수를 증가시킨다.\n\n이처럼 서비스를 운영 시 문제가 생겼을 때 후속 조취 작업은 필수인데 이러한 작업이 ‘사람’에 의존적이라면 실수할 여지가 있으며 이는 곧 ‘ 서비스 품질이 사람에 의해 바뀔 수 있다는 것입니다.’ **보편적인 자동화는 한계가 있고 이는 우리가 추구하는 완벽한 의미에서 자동화는 아닙니다. 따라서 O*rchestration*은 후속 조치에 대한 것까지 자동화 해주는 것을 목표로 등장하였고 컨테이너 환경에서는 필수적인 기능들이 되었습니다.**\n\n쿠버네티스는 오케스트레이션 도구로서 ‘Self Healing’ 을 통해 컨테이너를 지속적으로 정상 상태로 복구시켜주고 부하가 늘어나 처리량이 떨어지면, HPA를 통해 ‘Auto Scaling’**을 셀프로** 진행합니다. 이렇게 **쿠버네티스는 사람이 진행하던 ‘후속 조취’를 자체적으로 제공하기 때문에 휴먼 에러로 인한 품질이 저하가 발생하지 않으며, 보다 완벽한 자동으로 제공하기 때문에 엔지니어의 운영 코스트를 절감 시켜 다른 생산적인 작업에 리소스를 투입할 수 있게 해줍니다.**\n\n### 그 외 어떤 도구들이 있을까?\n\n쿠버네티스는 컨테이너를 오케스트레이션 하는 도구이며 쉽게 생각하면 컨테이너 관리 도구입니다. 따라서 컨테이너 관리를 위해 꼭 쿠버네티스만을 사용해야 하는 것은 아닙니다. 오히려 단순 컨테이너를 관리하는 것이 목적이면 꼭 쿠버네티스를 사용할 필요는 없으며 대표적으로 아래의 대안들이 존재합니다.\n\n1. Docker Compose\n2. Docker Swarm\n3. AWS ECS\n4. 서버리스 서비스들\n\n이렇게 가장 간단한 Docker Compose 부터 AWS의 ECS 그리고 다양한 서버리스 제품들까지 대안이 존재합니다. 실제로 저희도 Docker Compose만으로 간단한 3tier architecture를 사용했었습니다. 하지만 Docker Compose 만으로는 위 문제들을 해결할 수 없었고 컨테이너 기반으로 서비스를 더 잘 운영하기 위해선 쿠버네티스가 많은 도움을 준다고 생각하여 쿠버네티스를 도입하였습니다.\n\n추가로 클라우드 환경이라면 컨테이너 오케스트레이션 도구로 AWS ECS 또한 강력합니다. 하지만 ECS는 결국 AWS 의존성이 높고 이식성이 떨어지며 쿠버네티스의 서비스와 같은 로드밸런서의 부재로 컨테이너 레벨에서 로드밸런싱과 서비스 디스커버리 측면에서 한계가 뚜렷합니다.\n\n---\n\n## 그렇다면 무엇이 쿠버네티스를 표준으로 만들었고 우리가 쿠버네티스를 사용하는 이유!\n\n대안들이 존재하지만 쿠버네티스는 컨테이너 오케스트레이션 표준이되었다. 무엇이 컨테이너 오케이스트레이션 도구에서 표준으로 자리 잡게 했을까요?\n\n![Image](kubernetes.png)\n\n1. **높은 이식성과 쿠버네티스 에코시스템:**\n    1. 쿠버네티스를 사용하면 다양한 클라우드 환경 및 온프레미스 환경에서도 일관된 방식으로 애플리케이션을 배포하고 운영할 수 있게 해줍니다.\n    2. 쿠버네티스는 CNCF에서 관리하는 오픈소스이기 때문에 기능들이 빠르게 확장되고 있으며 커뮤니티기반의 강력한 에코 시스템을 확보했습니다. 이러한 에코 시스템들은 운영에 대한 코스트를 낮춥니다.\n2. **클러스터링:**\n    1. 쿠버네티스는 Control Plane, Data Plane으로 크게 두 가지 클러스터링을 지원합니다. 따라서 하나의 노드가 Down되어도 나머지 정상 노드를 활용해 비즈니스를 가동시킬 수 있습니다.\n3. **유연한 스케줄링:**\n    1. 쿠버네티스는 단순한 스케줄링이 아니라 Node의 상태에 따라 최선의 스케줄링을 하고자 노력합니다.\n    2. 쿠버네티스는 Application의 특성을 고려해 유연한 스케줄링을 제공합니다. 예를 들어 AI 기능이 필요하다면 GPU가 설치된 노드에 배치하는 것이 가능하며, 토폴로지를 제공해 내결함성을 높일 수 있습니다. \n4. **손쉬운 네트워크 관리:**\n    1. 쿠버네티스는 CNI 플러그인이라는 가상의 네트워크를 활용해 컨테이너간 통신 컨테이너에 IP 할당 등등 다양한 네트워크 문제를 외부 의존성 없이 자체적으로 해결할 수 있게 지원합니다.\n5. **서비스 디스커버리와 로드 밸런싱:**\n    1. Pod들이 동적으로 생성되고 소멸되기 때문에, 서비스 간 통신을 IP 기반이 아닌 DNS 기반으로 통신할 수 있게 지원합니다.\n    2. 쿠버네티스는  로드 밸런싱을 이용해 Reliability를 높일 수 있는데, Not Ready 상태의 Pod들은 트래픽에서 자동으로 제외시켜 고객의 실패 경험을 최소화 시킬 수 있습니다. \n6. **셀프 힐링과 오토스케일링:**\n    1. 내부적으로 제어루프 개념이 존재하기 때문에 Pod가 죽었을 때와 같이 Desired State에서 달라졌을 때 자동으로 Pod를 생성하는 등의 **현재 상태가 목표 상태와 일치하도록 시스템을 조정**하는 방식으로 작동한다.\n    2. Application의 처리량이 떨어져 Latency가 늘어난다면 HPA, VPA를 사용해 탄력적인 스케일 인/아웃 을 지원합니다. 나아가 Node의 Resource Pressure에도 Cluster Autoscaler를 사용해 노드 자체도 동적으로 조절할 수 있습니다.\n7. **볼륨 관리:**\n    1. PV와 PVC를 분리하여 스토리지 기술과 애플리케이션의 커플링을 줄입니다. 이를 통해 컨테이너는 Row Level의 Storage 기술에 종속적이지 않고 PVC 만을 사용해 유연하게 볼륨을 구축할 수 있습니다.\n    2. 이러한 특징은 이식성을 높이며, 비교적 비용이 높은 Raw Level의 기술 변경에도 안정성을 제공합니다. \n8. **최적화된 GitOps:**\n    1. 쿠버네티스는 Desired State를 유지하고자 합니다. 또 이러한 Desired State는 YAML 파일을 사용하여 선언적인 방식으로 관리됩니다.\n    2. 따라서 형상 코드의 형태로 (IaC) Git을 **Source of Truth로** 이용해 관리하며 손쉬운 롤백과 히스토리 추적을 지원하여 신뢰성을 높일 수 있습니다.\n\n이러한 매커니즘들은 결국 컨테이너 환경에서 서비스를 운영할 때 고민해야하는 것들입니다. 이러한 고민들에 대한 해답을 쿠버네티스가 가장 잘 지원하기 때문에 쿠버네티스가 핵심이자 표준이 되었다 생각합니다.\n\n---\n\n## 다시 생각해보는,  ‘우리는 왜 쿠버네티스를 선택했나’\n\n위에서 쿠버네티스가 무엇이고 왜 표준이 되었는지 쿠버네티스의 강점들을 정리했습니다. 물론 쿠버네티스가 ‘실버 불릿’은 아니기 때문에 트레이드 오프가 발생하지만, 지금 다시 의사결정을 하라고 해도 쿠버네티스를 선택할 것 같습니다. 그렇다면 왜 그런 선택을 할지 한 번 정리해보겠습니다.\n\n만약, 지금 다시 의사결정을 해야 한다면 Docker Swarm과 비교해볼 수 있을 것 같습니다. Docker Swarm은 Docker engine에 내장되어있는 Cluster management, Orchestration Tool이며 Kubernetes 처럼 클러스터링을 지원하며 어느정도의 셀프 힐링도 지원합니다. 하지만 도커스웜은 소규모 서비스에 적합하다 라는 내용을 쉽게 볼 수 있습니다. 왜 그럴까요?\n\n### **[도커 스웜의 한계점]**\n\n1. **서비스 신뢰성을 보장하기엔 부족한 기능들:** 서비스의 신뢰성을 위해선 ‘고가용성’과 ‘확장성’이 중요한 포인트입니다. 도커 스웜은 컨테이너 레벨에서의 복구를 지원하지만 많이 부족합니다. (PDB도 없음)\n무엇보다 컨테이너에 대한 `Health Check`, `Readiness` 기능이 없기 때문에 컨테이너가 비정상적으로 동작하고 있어도 트래픽은 그대로 전달되기 때문에 고객의 트래픽이 지속적으로 실패할 수 있습니다. 반면, K8s는 자동으로 비정상 파드를 트래픽 대상에서 지워 실패 경험을 최소화 합니다. \n    \n    또, 노드 레벨에서 장애가 났을 때 조취하는 것이 부족합니다. 쿠버네티스는 `Unready` 상태의 노드가 발견되면 즉시,  정상적인 상태의 노드로 파드의 스케줄링을 다시합니다. 이렇게 K8s는 신뢰성을 높일 수 있는 여러가지 자동화 매커니즘이 존재하지만 도커 스웜은 부족합니다.\n    \n2. **부족한 리소스 타입:** `StatefulSet`**,** `DaemonSet`, `Job` 등등 쿠버네티스에는 단순 컨테이너를 넘어 컨테이너를 활용해 보다 다양한 종류의 서비스를 운영할 수 있습니다. 컨테이너는 Stateless 하다는 특징이 있는데 이는 큰 장점이지만 단점이 될 때도 있습니다. 예를 들어 DB 같은 서비스는 Stateful 해야 하며 Stateful한 리소스들의 고유성을 보장하고 몇번을 스케줄링해도 동일한 노드에 스케줄링 해줍니다. 하지만 도커 스웜은 이러한 기능들이 존재하지 않아 애플리케이션 성격에 따라 유연한 대처가 불가능합니다.\n3. **부족한 배포 시스템:** Kubernetes에는 `Deployment` 를 이용해 `RollingUpdate`를  기본적으로 지원합니다. Docker Swarm도 service update로 가능하지만 세밀한 제어가 부족합니다. 쿠버네티스는 graceful down을 지원할 수 있으며, `maxUnavailable` 를 통해 최소로 유지할 파드를 선언해, 서비스의 순단을 방지합니다. \n4. **스케줄링 유연도가 떨어진다:** 쿠버네티스는 어피니티를 통해 선호하는 곳으로 컨테이너를 스케줄링할 수 있게 도우며 토폴로지를 지원해 분산 배치를 지원 하지만 도커 스웜에는 이러한 기능이 없습니다. 나아가 Resource에 대한 Request가 없어 최소한의 자원을 보장받는 것도 어렵습니다. 또, Node가 Pressure를 받을 경우, Evict 되어야할 필요가 있는데 이 경우, QoS 클래스라는 개념을 이용해 Evict 우선 순위를 결정하여 주요 서비스의 컴퓨팅 리소스를 최대한 안전하게 지킬 수 있습니다.\n\n이렇게 도커 스웜은 많은 부분에서 오케스트레이션 도구의 표준이 되기 어려운 형태입니다. 이러한 부족함은 고객사의 폐쇄망에 서비스를 전달하고 운영하는데 있어 신뢰도를 갖추기 어렵다. 판단됩니다. 따라서 지금에서 의사결정을 해도 쿠버네티스를 선택할 것 같습니다.\n\n---\n\n## 어떤 트레이드 오프를 가져야할까? - 앞으로의 숙제\n\n지금까지 쿠버네티에 대해 정리하고 도커 스웜과 비교하며 쿠버네티스 라는 의사결정 배경을 고민해봤습니다. 아시겠지만 쿠버네티스를 도입했다고 끝이 아닙니다. 쿠버네티스는 복잡도가 높으며 특히나 EKS처럼 Managed가 아니기 때문에 많은 부분을 신경써야만 보다 안정적인 운영이 가능해집니다.\n\n1. **가시성을 높여야합니다.**\n    1. 비즈니스를 담당하는 애플리케이션의 가시성, 클러스터 운영의 Core인 `Control Plane` 에 대한 가시성 모두 챙겨야합니다. 관리하는 Workload들이 늘어날 수록 `Control Plane` 의 부하는 높아지고 Control Plane이 죽으면 전체 장애로 이어집니다.\n2. **물리 머신 레벨에서도 최대한 무중단를 지원해야 합니다.**\n    1. 쿠버네티스 버전 업, 노드의 장애로 인한 교체 과정에서 비즈니스는 자체가 완전히 멈추는 것을 피하고자 최대한 무중단을 지원할 수 있어야 합니다.\n    2. 이를 통해 클러스터에 대한 MTTR를 높이고 SLA를 준수할 수 있게 노력해야 합니다.\n\n---\n\n## 마무리\n\n지금까지 머리속에 뒤죽박죽으로 있던 것들을 정리해봤습니다. 이 과정에서 처음 목표 했던 Why에 대한 답변도 생긴 것 같습니다. 특히, 도커 스웜의 한계점을 명확히 이해하고 우리가 왜 쿠버네티스를 선택해야 했는지 보다 명확해진 시간이었던 것 같습니다. \n\n앞으로는 쿠버네티스 클러스터 구축의 모범 사례도 학습하며 우리의 약점들을 어떻게 보완할 수 있을지 고민해보도록 할 예정입니다."},{"excerpt":"들어가며 비즈니스를 운영하는 엔지니어 입장에서 가장 Risky 한 것은 서비스 장애로 인한 사용자 경험을 저해시켜 서비스의 신뢰도를 떨어트리는 것이라 생각합니다. 그렇다고 해서 장애가 0%인 서비스가 있는 것은 아닙니다. 하지만 “장애가 없는 서비스는 없어!” 하고 방치하는 것은 무책임한 것 처사라 생각합니다. 우리의 역할은 장애를 최소한으로 줄이는 것이…","fields":{"slug":"/쿠버네티스에서-파드-운영-하기/"},"frontmatter":{"date":"January 05, 2025","title":"쿠버네티스트 환경에서 Pod 안정적으로 운영하기","tags":["Kubernetes","DevOps"]},"rawMarkdownBody":"\n\n## 들어가며\n\n**비즈니스를 운영하는 엔지니어 입장에서 가장 Risky 한 것은 서비스 장애로 인한 사용자 경험을 저해시켜 서비스의 신뢰도를 떨어트리는 것이라 생각합니다.** 그렇다고 해서 장애가 0%인 서비스가 있는 것은 아닙니다. 하지만 “장애가 없는 서비스는 없어!” 하고 방치하는 것은 무책임한 것 처사라 생각합니다.\n\n우리의 역할은 **장애를 최소한으로 줄이는 것이 우리의 역할이자 책임이라 생각합니다**. 특히 DevOps  Engineering을 한다면 그 책임과 역할이 더욱 클 것입니다. 그렇기에 **이번 포스팅을 통해 조금 더 안정적으로 서비스를 안정적으로 운영하기 위한 여러가지 방법들을 정리합니다.**\n\n---\n\n## 1. Deployment 를 활용하라\n\n쿠버네티스 환경에서 서비스를 운영한다면 안정성을 높일 수 있는 메커니즘을 제공합니다. 따라서 쿠버네티스 환경에서는 어렵지 않게 안정성을 높일 수 있는데 그 시작을 위한 첫 번째는 `Deployment`라는 Workload 를 활용하는 것입니다.\n\n쿠버네티스의 Deployment는 애플리케이션의 선언적 업데이트와 롤백을 관리하는 방법을 제공하는 API 오브젝트이며 다음과 같은 특징들을 가지고 있습니다.\n\n1. **파드 관리 및 업데이트:** Deployment는 ReplicaSet(레플리카셋)을 사용하여 지정된 수의 파드 복제본을 유지 관리합니다. 사용자는 Deployment를 통해 애플리케이션을 업데이트할 때 새로운 이미지로 Pod를 안전하게 Rollout 할 수 있습니다.\n2. **롤백:** Deployment는 변경 사항을 쉽게 되돌릴 수 있도록 지원하여, 새로운 업데이트에 문제가 있을 때 이전 Revision으로 롤백 할 수 있는 기능을 제공합니다.\n3. **Probe**: Deployment는 업데이트 중에 파드의 상태를 모니터링하고, 정해진 기준에 맞지 않는 경우 재시작시켜 문제를 해결할 수 있도록 합니다.\n\nDeployment의 이러한 특징들은 Pod의 안정성을 높이는데 크게 기여합니다. 특히 Probe 메커니즘과 Replica는 안정성의 핵심이라 볼 수 있으며 Rollback을 통해 문제를 빠르게 원복 시키는 것이 가능합니다.\n\nDeployment를 사용해 서비스를 운영할 때는 Replica Count를 2개 이상으로 고정하는 것을 추천하며 하나의 Pod가 Down 되어도 Replica를 통해 트래픽을 지속적으로 처리 가능합니다.\n\n하지만 Replica 설정으로만 모든 트래픽을 처리할 수 있는 것은 아닙니다. Kubernetes 입장에서 Pod의 상태가 정상이지만 애플리케이션이 트래픽을 처리할 수 없는 상태일 수 없기 때문입니다. 따라서 트래픽을 처리할 수 없는 Pod로 트래픽을 보내지 않는 메커니즘이 필요한데 이는 **Probe**를 통해 달성할 수 있습니다.\n\n**Probe**에는 `startup`, `liveness`, `readiness`이 있습니다. (각각의 특징은 여기서 다루지 않고 다음에 다루도록 하겠습니다.) 이러한 Probe들을 활용하면 Kubernetes는 Pod의 상태를 판단할 수있게되고, Healthy한 Pod로만 트래픽을 보내어 트래픽을 안정적으로 처리 할 수 있게됩니다.\n\n### **핵심 정리**\n\n1. Replica는 최소 2개이상\n2. 다양한 Probe 설정하기 \n\n---\n\n## 2. 분산배치 (토폴리지 분산) 하라\n\n서비스를 운영할 때 Node들은 Availability Zone을 다르게 설정합니다. 이러한 메커니즘은 하나의 IDC에 문제가 생겨도 전체 서비스에 영향 가는 것을 막기 위한 것인데 Pod도 동일합니다. Pod또한 Node 별로 분산배치하여 하나의 Node가 죽었을 때 모든 Pod이 죽지 않도록 해야합니다.\n\n\n기본 설정의 Deployment를 통해 Replica를 운영한다면 Node에는 같은 Pod가 여러 개 동작할 수 있습니다. 운이 좋지 않다면 하나의 Node에 Replica들이 모두 분포될 수 있는데 이때 Node가 중단된다면, 전체 서비스가 Down된 것이 됩니다. 따라서 하나의 Node에 모든 Replica들이 분포되지 않도록 분산 배치하는 것이 중요합니다. 분산배치를 위한 메커니즘 크게 두 가지입니다.\n\n1. **Pod Anti Affinity**\n2. **topologySpreadConstraints**\n\n**Pod Anti Affinity**\n\n- **Pod AntiAffinity는 특정 Pod들이 서로 다른 노드에 배치되도록 하는 설정입니다.** 예를 들어, 높은 가용성을 위해 같은 서비스의 여러 인스턴스가 같은 노드에 모두 위치하지 않도록 할 수 있습니다.\n- AntiAffinity는 주로 Label Selector를 사용하여 특정 레이블을 가진 Pod들과의 근접성을 제어합니다. 예를 들어, 같은 애플리케이션의 다른 인스턴스와는 다른 노드에 배치되어야 함을 명시할 수 있습니다.\n\n```yaml\n---\napiVersionL apps/v1\nkind: Deployment\nspec:\n  replicas: 2\n  template: \n    spec:\n      containers:\n      - name: my-container\n        ....\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: \"app\"\n                    operator: In\n                    values:\n                      - myapp\n              topologyKey: \"kubernetes.io/hostname\"\n```\n\n**topologySpreadConstraints**\n\n- topologySpreadConstraints는 클러스터 내의 특정 토폴로지(예: 노드, 랙, 존 등)에 걸쳐 Pod들이 균등하게 분포되도록 하는 설정입니다. 이는 클러스터의 리소스 사용률을 최적화하고, 특정 지역에 서비스 중단이 발생했을 때 영향을 최소화하는 데 유용합니다.\n- 사용자는 `maxSkew`, `topologyKey`, `whenUnsatisfiable` 같은 파라미터를 설정하여 원하는 분산 정도와 행동을 정의할 수 있습니다. 예를 들어, `maxSkew: 1`은 지정된 토폴로지 경계 내에서모든 Pod의 수가 하나 이상 차이 나지 않도록 한다는 것을 의미합니다.\n\n```yaml\n---\napiVersion: apps/v1\nkind: Deployment\nspec:\n  replicas: 2\n  template: \n    spec:\n      topologySpreadConstraints:\n        - maxSkew: 1\n          topologyKey: \"kubernetes.io/hostname\"\n          whenUnsatisfiable: DoNotSchedule\n          labelSelector:\n            matchLabels:\n              app: myapp\n      containers:\n      - name: mycontainer\n        ....\n```\n\n- **topologyKey**: Pod들이 분산될 기준이 되는 탑올로지 키를 지정합니다. 여기서는 `\"kubernetes.io/hostname\"`을 사용하여 각 Pod가 다른 호스트에 배치되도록 합니다.\n- **whenUnsatisfiable**: 스케줄링 옵션이 만족되지 않을 때의 행동을 지정합니다. `DoNotSchedule`은 조건을 만족하는 노드가 없을 경우 새로운 Pod를 스케줄하지 않습니다.\n- **labelSelector**: 이 제약조건이 적용될 Pod들의 Label Selector입니다. 이 경우 `app: myapp` 레이블을 가진 Pod들이 대상입니다.\n\n정리하면 `Pod AntiAffinity`는 주로 다른 특정 Pod와의 배치를 회피하는 데 초점을 맞추는 반면, `topologySpreadConstraints`는 클러스터 전반에 걸쳐 Pod의 균등한 분포를 조정하는 데 더 적합합니다.\n\n---\n\n## 3. Graceful Down을 설정하라\n\nGraceful Shtudown 설정은 Pod가 실행중인 작업을 안전하게 종료한 후, Pod를 종료시키는 것을 의미합니다. 만약 Pod가 실행 중인 작업이 안전하게 종료되지 않고 종료될 경우 리소스 낭비(DB 커넥션 반납실패)와 네트워크 입장에서는 갑자기 연결이 끊기는 현상과 같은 장애가 발생합니다.\n{: .prompt-info }\n\nPod의 Life Cycle은 kubelet이 관장합니다. kubelet은 `SIGTERM` 시그널을 보내어 Graceful 한 종료를 유도하는데 Pod는 SIGTERM 시그널을 받으면 프로세스를 정리하고 종료할 준비를 합니다. 그러나, 일부 Pod은 `SIGTERM` 시그널을 무시하는 경우가 있는데  이 경우  kubelet은 `terminationGracePeriodSeconds` 에 지정된 시간 동안 대기하며, 이 시간 내에 컨테이너가 종료되지 않는다면 `SIGKILL` 시그널을 보내어 강제 종료시킵니다. 따라서 이렇게 `SIGKILL` 로 인해 종료된 Pod는 Graceful 하게 종료되지 못하기 때문에 리소스가 낭비 되거나 HTTP Connection이 끊어져 502 Error로 이어질 수 있습니다.  \n\n이를 방지하기 위해 Pod는 2가지 옵션을 통해 Gracefule Down을 지원합니다.\n\n1. **terminationGracePeriodSeconds:** terminationGracePeriodSeconds은 Pod를 안전하게 종료시키기 위한 설정 값으로 kubelet이 `SIGTERM` 시그널을 보낸 후부터 **완전히 종료될 때까지 기다리는 시간(초)입니다.** \n    \n    이 시간동안 Pod는 하던 일을 마무리하고 정상적으로 프로세스 자원들은 반납 후 죽습니다.\n    \n2. **preStop:** preStop은 Kubernetes에서 제공하는 Lifecycle hook 중 하나로, pod가 종료되기 전에 실행되는 Hook 입니다.  preStop은 terminationGracePeriodSeconds 값이 설정된 시간 내에 실행을 완료해야 하며, Pod가 종료되기 전 마지막 작업을 처리하도록 해줍니다.\n    \n    Pod이 종료될 때  종료 전에 DB 연결을 종료하고 트랜잭션을 Commit하고 종료해야 하거나 File System (FS)을 정리하고 종료해야 하는 상황 등이 있을 수 있습니다. 이 때는 terminationGracePeriodSeconds 만으로는 Graceful 한 종료를 보장할 수 없는데 이를 위해 **preStop이란 것이 존재합니다.**\n    \n\n### 만약 springboot를 사용한다면\n\nApplication에서 graceful 설정을 추가하고 preStop에 sleep 설정하는 것으로 달성할 수 있습니다. 추가로 preStop Hook을 통해 Kubernetes의 네트워크 리소스를 정리하는 시간을 벌어 종료되는 Pod에 트래픽을 전달하지 않도록 할 수 있습니다.\n\n\n```yaml\n---\nserver:\n  shutdown:\n   graceful \n\nspring:\n  lifecycle:\n      timeout-per-shutdown-phase: 10s\n\n```\n\nSpring Context는 종료 시점에 사용하던 bean들을 정리하는 등의 Context를 정리하는 코드를 shutdown-hook으로 추가합니다. \n\n```yaml\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: springboot\nspec:\n  containers:\n  - name: springboot\n    image: my-springboot\n\tlifecycle:\n      preStop:\n        exec:\n          command: \n            - \"sh\"\n            - \"-c\"\n            - \"sleep 30\"\n```\n\n`preStop`에 `sleep`이 필요한 이유는 SIGTERM을 받은 Pod에 대한 네트워크 리소스 정리를 하는데 시간이 필요하기 때문입니다. sleep하는 동안 Endpoints Controller에서 Pod의 IP를 지우고 API Server에 반영하여 kube proxy가 iptables 정보를 변경하는 시간을 버는 것입니다.  이러한 Update를 통해 더 이상 비정상 Pod에 트래픽을 보내지 않게합니다.\n\n---\n\n### 출처\n\n- https://wlsdn3004.tistory.com/14\n- https://yang1s.tistory.com/33"}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}